{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c6cf0f-0370-4908-a248-856d07e47c60",
   "metadata": {},
   "source": [
    "### Attempt to compute H*d (Block diagonal Hessian H, direction d)  \n",
    "\n",
    " First define a simple model (that is supported by Backpack):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1525587-1d61-408e-a49c-b78364594175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 10])\n",
      "torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import rand\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import (\n",
    "    GGNMP,\n",
    "    HMP,\n",
    "    KFAC,\n",
    "    KFLR,\n",
    "    KFRA,\n",
    "    PCHMP,\n",
    "    BatchDiagGGNExact,\n",
    "    BatchDiagGGNMC,\n",
    "    BatchDiagHessian,\n",
    "    BatchGrad,\n",
    "    BatchL2Grad,\n",
    "    DiagGGNExact,\n",
    "    DiagGGNMC,\n",
    "    DiagHessian,\n",
    "    SqrtGGNExact,\n",
    "    SqrtGGNMC,\n",
    "    SumGradSquared,\n",
    "    Variance,\n",
    ")\n",
    "from backpack.utils.examples import load_one_batch_mnist\n",
    "\n",
    "\n",
    "# Define a simple neural network with nn.ReLU instead of torch.relu\n",
    "# Define a simple neural network using Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),  # Use nn.ReLU module directly in Sequential\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# The following is only to create a somewhat learnable datasetw\n",
    "# Set dimensions\n",
    "num_samples = 1000\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "# Create input data X with random values\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Define a random weight matrix and bias for generating learnable y\n",
    "true_weights = torch.randn(input_dim, output_dim)\n",
    "true_bias = torch.randn(output_dim)\n",
    "\n",
    "# Generate target y as a linear combination of X plus some noise\n",
    "y = X @ true_weights + true_bias + 0.1 * torch.randn(num_samples, output_dim)\n",
    "\n",
    "# Check dimensions\n",
    "print(X.shape)  # Should be [1000, 10]\n",
    "print(y.shape)  # Should be [1000, 1]\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# IMPORTANT: extend youre model with backpack, otherwise the parameters will not be extended\n",
    "# Extend the model and criterion with BackPACK\n",
    "model = extend(model, use_converter=True) # Extend the loss function\n",
    "criterion = extend(criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13b4e7-bea8-46eb-9c09-be128f1d39ed",
   "metadata": {},
   "source": [
    "Next we want to do a training with only one minibatch and one iteration for test purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e341d015-4503-4647-b6a4-eb0f5d7d3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2186.820556640625\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 4.350311279296875\n",
      "-d^T g for torch.Size([5]): 2216.300048828125\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.23804143071174622\n",
      "-d^T g for torch.Size([1, 5]): 385.8699951171875\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 10.442930221557617\n",
      "-d^T g for torch.Size([1]): 135.07504272460938\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 1.4965215921401978\n",
      "Total d^T H d across all parameters: 16.527804523706436\n",
      "Total -d^T g across all parameters: 4924.065643310547\n",
      "a star:  297.92617847509734\n",
      "Epoch Number: 1001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2872.453125\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 5.157209873199463\n",
      "-d^T g for torch.Size([5]): 2352.77783203125\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.5297545194625854\n",
      "-d^T g for torch.Size([1, 5]): 1008.1906127929688\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 18.897186279296875\n",
      "-d^T g for torch.Size([1]): 117.62457275390625\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 1.441070318222046\n",
      "Total d^T H d across all parameters: 26.02522099018097\n",
      "Total -d^T g across all parameters: 6351.046142578125\n",
      "a star:  244.03428284178497\n",
      "Epoch Number: 2001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2440.56005859375\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 12.497196197509766\n",
      "-d^T g for torch.Size([5]): 2207.942626953125\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 1.1197521686553955\n",
      "-d^T g for torch.Size([1, 5]): 1122.490234375\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 61.12264633178711\n",
      "-d^T g for torch.Size([1]): 578.0111694335938\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 4.910340785980225\n",
      "Total d^T H d across all parameters: 79.6499354839325\n",
      "Total -d^T g across all parameters: 6349.004089355469\n",
      "a star:  79.71135255770695\n",
      "Epoch Number: 3001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 3030.33349609375\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 23.36457061767578\n",
      "-d^T g for torch.Size([5]): 2075.8125\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.5928422808647156\n",
      "-d^T g for torch.Size([1, 5]): 1326.23046875\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 37.40777587890625\n",
      "-d^T g for torch.Size([1]): 335.19427490234375\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 2.482125997543335\n",
      "Total d^T H d across all parameters: 63.84731477499008\n",
      "Total -d^T g across all parameters: 6767.570739746094\n",
      "a star:  105.99616855519017\n",
      "Epoch Number: 4001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2224.078857421875\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 8.57412338256836\n",
      "-d^T g for torch.Size([5]): 2166.254150390625\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.1896342635154724\n",
      "-d^T g for torch.Size([1, 5]): 2554.25341796875\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 151.29959106445312\n",
      "-d^T g for torch.Size([1]): 195.1287841796875\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 1.7827749252319336\n",
      "Total d^T H d across all parameters: 161.8461236357689\n",
      "Total -d^T g across all parameters: 7139.7152099609375\n",
      "a star:  44.11421817916113\n",
      "Epoch Number: 5001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2101.0634765625\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 5.364104270935059\n",
      "-d^T g for torch.Size([5]): 2225.945068359375\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.3044179081916809\n",
      "-d^T g for torch.Size([1, 5]): 4413.90478515625\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 304.2191162109375\n",
      "-d^T g for torch.Size([1]): 239.1497344970703\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 2.448962450027466\n",
      "Total d^T H d across all parameters: 312.3366008400917\n",
      "Total -d^T g across all parameters: 8980.063064575195\n",
      "a star:  28.751235174276754\n",
      "Epoch Number: 6001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2551.25\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 14.005874633789062\n",
      "-d^T g for torch.Size([5]): 2337.5849609375\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.7940649390220642\n",
      "-d^T g for torch.Size([1, 5]): 2522.54150390625\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 77.55523681640625\n",
      "-d^T g for torch.Size([1]): 19.15599822998047\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 0.22364753484725952\n",
      "Total d^T H d across all parameters: 92.57882392406464\n",
      "Total -d^T g across all parameters: 7430.5324630737305\n",
      "a star:  80.2616856352141\n",
      "Epoch Number: 7001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2484.98876953125\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 9.842354774475098\n",
      "-d^T g for torch.Size([5]): 2157.743896484375\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.3650834560394287\n",
      "-d^T g for torch.Size([1, 5]): 2325.6748046875\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 35.41227340698242\n",
      "-d^T g for torch.Size([1]): 0.6764578223228455\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 0.021361105144023895\n",
      "Total d^T H d across all parameters: 45.64107274264097\n",
      "Total -d^T g across all parameters: 6969.083928525448\n",
      "a star:  152.69325430397973\n",
      "Epoch Number: 8001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2359.23974609375\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 10.551889419555664\n",
      "-d^T g for torch.Size([5]): 2225.07861328125\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.6248900294303894\n",
      "-d^T g for torch.Size([1, 5]): 373.7197265625\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 11.308328628540039\n",
      "-d^T g for torch.Size([1]): 10.04246711730957\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 0.30283984541893005\n",
      "Total d^T H d across all parameters: 22.787947922945023\n",
      "Total -d^T g across all parameters: 4968.08055305481\n",
      "a star:  218.0135116893237\n",
      "Epoch Number: 9001\n",
      "Parameter Name: 0.weight\n",
      "Parameter Dimension: torch.Size([5, 10])\n",
      "*param.shape              5 10\n",
      "vec.shape:                torch.Size([1, 5, 10])\n",
      ".hmp(vec).shape:          torch.Size([1, 5, 10])\n",
      "Parameter Name: 0.bias\n",
      "Parameter Dimension: torch.Size([5])\n",
      "*param.shape              5\n",
      "vec.shape:                torch.Size([1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 5])\n",
      "Parameter Name: 2.weight\n",
      "Parameter Dimension: torch.Size([1, 5])\n",
      "*param.shape              1 5\n",
      "vec.shape:                torch.Size([1, 1, 5])\n",
      ".hmp(vec).shape:          torch.Size([1, 1, 5])\n",
      "Parameter Name: 2.bias\n",
      "Parameter Dimension: torch.Size([1])\n",
      "*param.shape              1\n",
      "vec.shape:                torch.Size([1, 1])\n",
      ".hmp(vec).shape:          torch.Size([1, 1])\n",
      "-d^T g for torch.Size([5, 10]): 2490.844482421875\n",
      "param.hmp(d).shape: torch.Size([5, 10])\n",
      "d^T H d for torch.Size([5, 10]): 8.044051170349121\n",
      "-d^T g for torch.Size([5]): 2377.10791015625\n",
      "param.hmp(d).shape: torch.Size([5])\n",
      "d^T H d for torch.Size([5]): 0.9274687767028809\n",
      "-d^T g for torch.Size([1, 5]): 1578.832275390625\n",
      "param.hmp(d).shape: torch.Size([1, 5])\n",
      "d^T H d for torch.Size([1, 5]): 40.22434997558594\n",
      "-d^T g for torch.Size([1]): 72.90078735351562\n",
      "param.hmp(d).shape: torch.Size([1])\n",
      "d^T H d for torch.Size([1]): 2.8003382682800293\n",
      "Total d^T H d across all parameters: 51.99620819091797\n",
      "Total -d^T g across all parameters: 6519.685455322266\n",
      "a star:  125.38770962162513\n",
      "Training complete!\n",
      "Maximum a_star value: 503.7458190917969\n",
      "Minimum a_star value: 24.045045852661133\n",
      "Standard deviation of a_star values: 85.88326263427734\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters for testing\n",
    "batch_size = 32\n",
    "n_epochs = 10000  # Only one epoch for testing\n",
    "epoch_count = 0 # for print statements\n",
    "# List to store all a_star values\n",
    "a_star_values = []\n",
    "\n",
    "# Select one minibatch from the dataset\n",
    "X_batch = X[:batch_size]\n",
    "y_batch = y[:batch_size]\n",
    "\n",
    "# Training loop with only one minibatch\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    print_bool = True if epoch_count % 1000 == 0 else False\n",
    "    # Forward pass\n",
    "    y_pred = model(X_batch)\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "\n",
    "    with backpack(\n",
    "        HMP(),      # possible problem with comma, check if run fails\n",
    "    ):\n",
    "        loss.backward()\n",
    "\n",
    "    V = 1\n",
    "    if print_bool:\n",
    "        print(\"Epoch Number:\", epoch_count + 1)\n",
    "        for name, param in model.named_parameters():\n",
    "            # Access parameter name\n",
    "            print(\"Parameter Name:\", name)\n",
    "            print(\"Parameter Dimension:\", param.shape)\n",
    "            vec = rand(V, *param.shape)\n",
    "            print(\"*param.shape             \", *param.shape)\n",
    "            print(\"vec.shape:               \", vec.shape)\n",
    "            print(\".hmp(vec).shape:         \", param.hmp(vec).shape)\n",
    "\n",
    "    g_list = []  # List to store flattened gradients\n",
    "    d_list = []  # List to store flattened directions d_t\n",
    "    hessian_d_products = []  # To store d^T H d for each parameter\n",
    "    d_g_products = []  # To store -d^T g for each parameter\n",
    "\n",
    "    # Loop over parameters to compute and apply hmp in chunks\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            # Flatten and store the gradient for this parameter\n",
    "            g_list.append(param.grad.view(-1))\n",
    "\n",
    "            # Initialize optimizer state if it doesn't exist\n",
    "        if param not in optimizer.state:\n",
    "            optimizer.state[param]['exp_avg'] = torch.zeros_like(param.data)\n",
    "            optimizer.state[param]['exp_avg_sq'] = torch.zeros_like(param.data)\n",
    "            optimizer.state[param]['step'] = torch.tensor(0)  # Initialize step as tensor\n",
    "\n",
    "        # Ensure 'step' is a tensor\n",
    "        if isinstance(optimizer.state[param]['step'], int):\n",
    "            optimizer.state[param]['step'] = torch.tensor(optimizer.state[param]['step'])\n",
    "\n",
    "        # Get Adam's internal state (first and second moments)\n",
    "        m_t = optimizer.state[param]['exp_avg']        # First moment (moving average of gradients)\n",
    "        v_t = optimizer.state[param]['exp_avg_sq']     # Second moment (moving average of squared gradients)\n",
    "\n",
    "        # Bias correction for moments\n",
    "        beta1, beta2 = optimizer.defaults['betas']\n",
    "        optimizer.state[param]['step'] += 1  # Increment step as tensor\n",
    "        t = optimizer.state[param]['step'].item()  # Convert step tensor to int\n",
    "\n",
    "        m_t_hat = m_t / (1 - beta1**t)  # Bias-corrected first moment\n",
    "        v_t_hat = v_t / (1 - beta2**t)  # Bias-corrected second moment\n",
    "\n",
    "        # Compute Adam's update direction d_t\n",
    "        d_t = -m_t_hat / (torch.sqrt(v_t_hat) + optimizer.defaults['eps'])\n",
    "\n",
    "        # Flatten the direction d_t and append it to the list\n",
    "        d_list.append(d_t.view(-1))\n",
    "\n",
    "        # Compute -d^T g for this parameter\n",
    "        d_flat = d_t.view(-1)  # Flatten d\n",
    "        g_flat = param.grad.view(-1)  # Flatten the gradient g\n",
    "        d_g_product = -torch.dot(d_flat, g_flat)  # Compute -d^T g\n",
    "        d_g_products.append(d_g_product.item())  # Store the result as a scalar\n",
    "        \n",
    "        if print_bool:\n",
    "            print(f\"-d^T g for {param.shape}: {d_g_product}\")\n",
    "\n",
    "        # Reshape d_t to match the parameter's shape\n",
    "        vec = d_t.view(*param.shape)\n",
    "\n",
    "        # Perform the param.hmp(d) operation to compute H * d\n",
    "        hmp_output = param.hmp(vec)\n",
    "\n",
    "        # Compute d^T * H * d for this parameter\n",
    "        d_hmp_d = torch.dot(vec.view(-1), hmp_output.view(-1))  # Equivalent to d^T H d\n",
    "        hessian_d_products.append(d_hmp_d.item())  # Store the result as a scalar\n",
    "\n",
    "        if print_bool:\n",
    "            print(f\"param.hmp(d).shape: {hmp_output.shape}\")\n",
    "            print(f\"d^T H d for {param.shape}: {d_hmp_d}\")\n",
    "\n",
    "    # Now hessian_d_products contains d^T H d for each parameter.\n",
    "    total_d_H_d = sum(hessian_d_products)\n",
    "    if print_bool:\n",
    "        print(f\"Total d^T H d across all parameters: {total_d_H_d}\")\n",
    "\n",
    "    # Now d_g_products contains -d^T g for each parameter.\n",
    "    total_d_g = sum(d_g_products)\n",
    "    if print_bool:\n",
    "        print(f\"Total -d^T g across all parameters: {total_d_g}\")\n",
    "\n",
    "    # avoid division by zero\n",
    "    epsilon = 1e-8  # Small value to prevent division by zero\n",
    "    a_star = total_d_g / (total_d_H_d + epsilon)\n",
    "    # Store the a_star value\n",
    "    a_star_values.append(a_star)\n",
    "    \n",
    "    if print_bool:\n",
    "        print(\"a star: \", a_star)\n",
    "    \n",
    "\n",
    "    # Optimizer step (updates the parameters)\n",
    "    optimizer.step()\n",
    "    \n",
    "    epoch_count = epoch_count + 1\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# After the loop finishes\n",
    "a_star_tensor = torch.tensor(a_star_values)  # Convert list to a PyTorch tensor\n",
    "\n",
    "# Calculate statistics\n",
    "max_a_star = torch.max(a_star_tensor)\n",
    "min_a_star = torch.min(a_star_tensor)\n",
    "std_a_star = torch.std(a_star_tensor)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Maximum a_star value: {max_a_star.item()}\")\n",
    "print(f\"Minimum a_star value: {min_a_star.item()}\")\n",
    "print(f\"Standard deviation of a_star values: {std_a_star.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c561855-d0a0-4739-a2ae-e9080ca93af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (taylor)",
   "language": "python",
   "name": "taylor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
