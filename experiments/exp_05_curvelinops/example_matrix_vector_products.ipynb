{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Matrix-vector products\n",
    "\n",
    "This tutorial contains a basic demonstration how to set up ``LinearOperators``\n",
    "for the Hessian and the GGN and how to multiply them to a vector.\n",
    "\n",
    "First, the imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from curvlinops import GGNLinearOperator, HessianLinearOperator\n",
    "from curvlinops.examples.functorch import functorch_ggn, functorch_hessian\n",
    "from curvlinops.examples.utils import report_nonclose\n",
    "\n",
    "# make deterministic\n",
    "torch.manual_seed(0)\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's create some toy data, a small MLP, and use mean-squared error as loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "N = 4\n",
    "D_in = 7\n",
    "D_hidden = 5\n",
    "D_out = 3\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = torch.rand(N, D_in).to(DEVICE)\n",
    "y = torch.rand(N, D_out).to(DEVICE)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, D_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(D_hidden, D_hidden),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(D_hidden, D_out),\n",
    ").to(DEVICE)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "loss_function = nn.MSELoss(reduction=\"mean\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian-vector products\n",
    "\n",
    "Setting up a linear operator for the Hessian is straightforward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = [(X, y)]\n",
    "H = HessianLinearOperator(model, loss_function, params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now multiply by the Hessian. This operation will be carried out in\n",
    "PyTorch under the hood, but the operator is compatible with ``scipy``, so we\n",
    "can just pass a ``numpy`` vector to the matrix-multiplication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "D = H.shape[0]\n",
    "v = numpy.random.rand(D)\n",
    "\n",
    "Hv = H @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the result, we compute the Hessian using ``functorch``, using a\n",
    "utility function from ``curvlinops.examples``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "H_mat = functorch_hessian(model, loss_function, params, data).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the multiplication onto ``v`` leads to the same result:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Hv_functorch = H_mat @ v\n",
    "\n",
    "print(\"Comparing Hessian-vector product with functorch's Hessian-vector product.\")\n",
    "report_nonclose(Hv, Hv_functorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian-matrix products\n",
    "\n",
    "We can also compute the Hessian's matrix representation with the linear\n",
    "operator, simply by multiplying it onto the identity matrix. (Of course, this\n",
    "only works if the Hessian is small enough.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "H_mat_from_linop = H @ numpy.eye(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should yield the same matrix as with :code:`functorch`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Comparing Hessian with functorch's Hessian.\")\n",
    "report_nonclose(H_mat, H_mat_from_linop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, here's a visualization of the Hessian.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Hessian\")\n",
    "plt.imshow(H_mat)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GGN-vector products\n",
    "\n",
    "Setting up a linear operator for the Fisher/GGN is identical to the Hessian.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GGN = GGNLinearOperator(model, loss_function, params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute a GGN-vector product.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "D = H.shape[0]\n",
    "v = numpy.random.rand(D)\n",
    "\n",
    "GGNv = GGN @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the result, we will use ``functorch`` to compute the GGN. For that,\n",
    "we use that the GGN corresponds to the Hessian if we replace the neural\n",
    "network by its linearization. This is implemented in a utility function of\n",
    ":code:`curvlinops.examples`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GGN_mat = functorch_ggn(model, loss_function, params, data).detach().cpu().numpy()\n",
    "\n",
    "GGNv_functorch = GGN_mat @ v\n",
    "\n",
    "print(\"Comparing GGN-vector product with functorch's GGN-vector product.\")\n",
    "report_nonclose(GGNv, GGNv_functorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GGN-matrix products\n",
    "\n",
    "We can also compute the GGN matrix representation with the linear operator,\n",
    "simply by multiplying it onto the identity matrix. (Of course, this only\n",
    "works if the GGN is small enough.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GGN_mat_from_linop = GGN @ numpy.eye(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should yield the same matrix as with :code:`functorch`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Comparing GGN with functorch's GGN.\")\n",
    "report_nonclose(GGN_mat, GGN_mat_from_linop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, here's a visualization of the GGN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"GGN\")\n",
    "plt.imshow(GGN_mat)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual comparison: Hessian and GGN\n",
    "\n",
    "To conclude, let's plot both the Hessian and GGN using the same limits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "min_value = min(GGN_mat.min(), H_mat.min())\n",
    "max_value = max(GGN_mat.max(), H_mat.max())\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].set_title(\"Hessian\")\n",
    "ax[0].imshow(H_mat, vmin=min_value, vmax=max_value)\n",
    "ax[1].set_title(\"GGN\")\n",
    "ax[1].imshow(GGN_mat, vmin=min_value, vmax=max_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
